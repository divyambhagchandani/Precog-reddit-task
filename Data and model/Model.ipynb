{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import gensim\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "client = pymongo.MongoClient(\"mongodb+srv://admin:divyam@precog-z500c.mongodb.net/test?retryWrites=true&w=majority\")\n",
    "mydb = client.get_database(\"India\")\n",
    "database=mydb.reddit_india\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts=list(database.find())\n",
    "df=pd.DataFrame(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = BeautifulSoup(text, \"lxml\").text\n",
    "    text = text.lower() \n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) \n",
    "    text = BAD_SYMBOLS_RE.sub('', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS)\n",
    "    return text\n",
    "df=df[df['flair'].notnull()]\n",
    "df=df[df['post'].notnull()]\n",
    "# df['all'] = df['all'].apply(clean_text)\n",
    "# df['all'].apply(lambda x: len(x.split(' '))).sum()\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.title\n",
    "y = df.flair\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AskIndia', 'Policy Economy', 'Politics', 'Non-Political',\n",
       "       'Reddiquette', 'Scheduled', 'ask', 'Dominant Policy', 'Policy',\n",
       "       'Sports', 'Science Technology', 'netneutrality', 'Photography',\n",
       "       'Business Finance Policy', 'Food', ''], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['flair'].value_counts()\n",
    "df.count()\n",
    "uni_flairs=df.flair.unique()\n",
    "uni_flairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.4949127906976744\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "               AskIndia       0.00      0.00      0.00         1\n",
      "         Policy Economy       0.46      0.95      0.62       320\n",
      "               Politics       1.00      0.20      0.33        35\n",
      "          Non-Political       0.00      0.00      0.00        44\n",
      "            Reddiquette       0.00      0.00      0.00        17\n",
      "              Scheduled       0.47      0.37      0.41       263\n",
      "                    ask       0.00      0.00      0.00        10\n",
      "        Dominant Policy       0.64      0.47      0.54        15\n",
      "                 Policy       0.60      0.03      0.05       112\n",
      "                 Sports       0.53      0.78      0.63       317\n",
      "     Science Technology       0.00      0.00      0.00        71\n",
      "          netneutrality       1.00      0.47      0.64        32\n",
      "            Photography       0.00      0.00      0.00        44\n",
      "Business Finance Policy       0.00      0.00      0.00        50\n",
      "                   Food       0.00      0.00      0.00        12\n",
      "                              0.33      0.03      0.06        33\n",
      "\n",
      "              micro avg       0.49      0.49      0.49      1376\n",
      "              macro avg       0.31      0.21      0.20      1376\n",
      "           weighted avg       0.43      0.49      0.40      1376\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/divyam/Desktop/Precog/env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=uni_flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6126453488372093\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "               AskIndia       0.00      0.00      0.00         1\n",
      "         Policy Economy       0.65      0.87      0.74       320\n",
      "               Politics       0.77      0.29      0.42        35\n",
      "          Non-Political       0.62      0.45      0.53        44\n",
      "            Reddiquette       0.00      0.00      0.00        17\n",
      "              Scheduled       0.54      0.49      0.51       263\n",
      "                    ask       0.67      0.40      0.50        10\n",
      "        Dominant Policy       0.64      0.60      0.62        15\n",
      "                 Policy       0.61      0.32      0.42       112\n",
      "                 Sports       0.62      0.76      0.68       317\n",
      "     Science Technology       0.77      0.28      0.41        71\n",
      "          netneutrality       0.78      0.91      0.84        32\n",
      "            Photography       0.40      0.32      0.35        44\n",
      "Business Finance Policy       0.82      0.46      0.59        50\n",
      "                   Food       0.67      0.17      0.27        12\n",
      "                              0.48      0.91      0.62        33\n",
      "\n",
      "              micro avg       0.61      0.61      0.61      1376\n",
      "              macro avg       0.56      0.45      0.47      1376\n",
      "           weighted avg       0.61      0.61      0.59      1376\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/divyam/Desktop/Precog/env/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=uni_flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/divyam/Desktop/Precog/env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/divyam/Desktop/Precog/env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6024709302325582\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "               AskIndia       0.00      0.00      0.00         1\n",
      "         Policy Economy       0.66      0.81      0.72       320\n",
      "               Politics       0.46      0.34      0.39        35\n",
      "          Non-Political       0.59      0.45      0.51        44\n",
      "            Reddiquette       0.20      0.06      0.09        17\n",
      "              Scheduled       0.50      0.54      0.52       263\n",
      "                    ask       0.67      0.40      0.50        10\n",
      "        Dominant Policy       0.90      0.60      0.72        15\n",
      "                 Policy       0.53      0.41      0.46       112\n",
      "                 Sports       0.64      0.67      0.66       317\n",
      "     Science Technology       0.57      0.46      0.51        71\n",
      "          netneutrality       0.89      1.00      0.94        32\n",
      "            Photography       0.44      0.39      0.41        44\n",
      "Business Finance Policy       0.83      0.38      0.52        50\n",
      "                   Food       0.33      0.17      0.22        12\n",
      "                              0.57      0.61      0.59        33\n",
      "\n",
      "              micro avg       0.60      0.60      0.60      1376\n",
      "              macro avg       0.55      0.46      0.49      1376\n",
      "           weighted avg       0.60      0.60      0.59      1376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
    "               ])\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=uni_flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.post\n",
    "y = df.flair\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.23909883720930233\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "               AskIndia       0.00      0.00      0.00         1\n",
      "         Policy Economy       0.23      1.00      0.38       320\n",
      "               Politics       0.00      0.00      0.00        35\n",
      "          Non-Political       0.00      0.00      0.00        44\n",
      "            Reddiquette       0.00      0.00      0.00        17\n",
      "              Scheduled       0.00      0.00      0.00       263\n",
      "                    ask       0.00      0.00      0.00        10\n",
      "        Dominant Policy       0.00      0.00      0.00        15\n",
      "                 Policy       0.00      0.00      0.00       112\n",
      "                 Sports       0.90      0.03      0.06       317\n",
      "     Science Technology       0.00      0.00      0.00        71\n",
      "          netneutrality       0.00      0.00      0.00        32\n",
      "            Photography       0.00      0.00      0.00        44\n",
      "Business Finance Policy       0.00      0.00      0.00        50\n",
      "                   Food       0.00      0.00      0.00        12\n",
      "                              0.00      0.00      0.00        33\n",
      "\n",
      "              micro avg       0.24      0.24      0.24      1376\n",
      "              macro avg       0.07      0.06      0.03      1376\n",
      "           weighted avg       0.26      0.24      0.10      1376\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/divyam/Desktop/Precog/env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=uni_flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/divyam/Desktop/Precog/env/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.3495639534883721\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "               AskIndia       0.00      0.00      0.00         1\n",
      "         Policy Economy       0.62      0.82      0.70       320\n",
      "               Politics       1.00      0.23      0.37        35\n",
      "          Non-Political       0.60      0.14      0.22        44\n",
      "            Reddiquette       0.00      0.00      0.00        17\n",
      "              Scheduled       0.48      0.11      0.18       263\n",
      "                    ask       0.00      0.00      0.00        10\n",
      "        Dominant Policy       0.59      0.67      0.62        15\n",
      "                 Policy       0.80      0.21      0.34       112\n",
      "                 Sports       0.73      0.20      0.32       317\n",
      "     Science Technology       0.68      0.18      0.29        71\n",
      "          netneutrality       0.67      0.81      0.73        32\n",
      "            Photography       0.83      0.11      0.20        44\n",
      "Business Finance Policy       0.40      0.04      0.07        50\n",
      "                   Food       1.00      0.08      0.15        12\n",
      "                              0.05      0.94      0.09        33\n",
      "\n",
      "              micro avg       0.35      0.35      0.35      1376\n",
      "              macro avg       0.53      0.28      0.27      1376\n",
      "           weighted avg       0.62      0.35      0.37      1376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=uni_flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/divyam/Desktop/Precog/env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/divyam/Desktop/Precog/env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.49273255813953487\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "               AskIndia       0.00      0.00      0.00         1\n",
      "         Policy Economy       0.68      0.69      0.69       320\n",
      "               Politics       1.00      0.29      0.44        35\n",
      "          Non-Political       1.00      0.16      0.27        44\n",
      "            Reddiquette       0.00      0.00      0.00        17\n",
      "              Scheduled       0.36      0.16      0.22       263\n",
      "                    ask       0.00      0.00      0.00        10\n",
      "        Dominant Policy       0.82      0.60      0.69        15\n",
      "                 Policy       0.71      0.24      0.36       112\n",
      "                 Sports       0.38      0.91      0.53       317\n",
      "     Science Technology       0.58      0.39      0.47        71\n",
      "          netneutrality       0.94      0.91      0.92        32\n",
      "            Photography       0.44      0.16      0.23        44\n",
      "Business Finance Policy       1.00      0.02      0.04        50\n",
      "                   Food       1.00      0.17      0.29        12\n",
      "                              0.69      0.27      0.39        33\n",
      "\n",
      "              micro avg       0.49      0.49      0.49      1376\n",
      "              macro avg       0.60      0.31      0.35      1376\n",
      "           weighted avg       0.57      0.49      0.45      1376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
    "               ])\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=uni_flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.url\n",
    "y = df.flair\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.4375\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "               AskIndia       0.00      0.00      0.00         1\n",
      "         Policy Economy       0.42      0.99      0.59       320\n",
      "               Politics       0.00      0.00      0.00        35\n",
      "          Non-Political       0.00      0.00      0.00        44\n",
      "            Reddiquette       0.00      0.00      0.00        17\n",
      "              Scheduled       0.53      0.30      0.39       263\n",
      "                    ask       0.00      0.00      0.00        10\n",
      "        Dominant Policy       0.00      0.00      0.00        15\n",
      "                 Policy       0.50      0.01      0.02       112\n",
      "                 Sports       0.43      0.64      0.52       317\n",
      "     Science Technology       0.00      0.00      0.00        71\n",
      "          netneutrality       0.00      0.00      0.00        32\n",
      "            Photography       0.00      0.00      0.00        44\n",
      "Business Finance Policy       0.00      0.00      0.00        50\n",
      "                   Food       0.00      0.00      0.00        12\n",
      "                              0.00      0.00      0.00        33\n",
      "\n",
      "              micro avg       0.44      0.44      0.44      1376\n",
      "              macro avg       0.12      0.12      0.09      1376\n",
      "           weighted avg       0.34      0.44      0.33      1376\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/divyam/Desktop/Precog/env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=uni_flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5348837209302325\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "               AskIndia       0.00      0.00      0.00         1\n",
      "         Policy Economy       0.49      0.99      0.66       320\n",
      "               Politics       0.44      0.11      0.18        35\n",
      "          Non-Political       0.80      0.18      0.30        44\n",
      "            Reddiquette       1.00      0.06      0.11        17\n",
      "              Scheduled       0.50      0.30      0.37       263\n",
      "                    ask       0.00      0.00      0.00        10\n",
      "        Dominant Policy       0.75      0.60      0.67        15\n",
      "                 Policy       0.61      0.31      0.41       112\n",
      "                 Sports       0.56      0.67      0.61       317\n",
      "     Science Technology       1.00      0.34      0.51        71\n",
      "          netneutrality       1.00      0.31      0.48        32\n",
      "            Photography       0.48      0.27      0.35        44\n",
      "Business Finance Policy       0.80      0.16      0.27        50\n",
      "                   Food       1.00      0.17      0.29        12\n",
      "                              0.37      0.42      0.39        33\n",
      "\n",
      "              micro avg       0.53      0.53      0.53      1376\n",
      "              macro avg       0.61      0.31      0.35      1376\n",
      "           weighted avg       0.58      0.53      0.49      1376\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/divyam/Desktop/Precog/env/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=uni_flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/divyam/Desktop/Precog/env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/divyam/Desktop/Precog/env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5479651162790697\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "               AskIndia       0.00      0.00      0.00         1\n",
      "         Policy Economy       0.50      0.99      0.66       320\n",
      "               Politics       0.36      0.11      0.17        35\n",
      "          Non-Political       0.48      0.27      0.35        44\n",
      "            Reddiquette       1.00      0.06      0.11        17\n",
      "              Scheduled       0.51      0.35      0.41       263\n",
      "                    ask       0.00      0.00      0.00        10\n",
      "        Dominant Policy       1.00      0.60      0.75        15\n",
      "                 Policy       0.58      0.41      0.48       112\n",
      "                 Sports       0.61      0.62      0.62       317\n",
      "     Science Technology       0.96      0.35      0.52        71\n",
      "          netneutrality       1.00      0.41      0.58        32\n",
      "            Photography       0.50      0.30      0.37        44\n",
      "Business Finance Policy       0.80      0.16      0.27        50\n",
      "                   Food       1.00      0.17      0.29        12\n",
      "                              0.48      0.42      0.45        33\n",
      "\n",
      "              micro avg       0.55      0.55      0.55      1376\n",
      "              macro avg       0.61      0.33      0.38      1376\n",
      "           weighted avg       0.59      0.55      0.51      1376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
    "               ])\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=uni_flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
